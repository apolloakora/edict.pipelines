---
#
# ######################## #
# playbook-worker-join.yml #
# ######################## #
#
# This playbook will attempt to join any worker node into the cluster being
# controlled by the master node. The prerequisites are
#
#   - the playbook-base-install.yml has been run for all nodes
#   - the master was successfully created with playbook-master-setup.yml
#   - (either) the worker/s have never attempted to join a cluster
#   - (or)     the worker/s have been reset with playbook-worker-reset.yml
#
# The master node is used to extract a join command which is then executed
# on the worker/s.
#
# A pre-check is to ssh into the master and validate that this command
# correctly produces a join command.
#
#    kubeadm token create --print-join-command
#
# In order to reverse this, first drain nodes from master, then run kubeadm reset on each node, and # then do a kubectl delete nodes from the master.
#
# kubectl drain {NODE-NAME} --delete-local-data --force --ignore-daemonsets
# sudo kubeadm reset --cri-socket /run/cri-dockerd.sock
# kubectl delete node {NODE-NAME}
#


- hosts: worker
  vars_files:
    - ./vars/variables.yml
  name: changing cgroup version to get orkers to start and get each worker node to join the kubernetes cluster
  tasks:

  - name: roll back cgroup by changing line
    become: true
    lineinfile:
      path: /etc/default/grub
      regexp: GRUB_CMDLINE_LINUX_DEFAULT=""
      line: GRUB_CMDLINE_LINUX_DEFAULT="systemd.unified_cgroup_hierarchy=0"

  - name: update grub
    become: true
    command: update-grub

  - name: Run kubeadm reset before init.
    become: true
    command: kubeadm reset --force --cri-socket /run/cri-dockerd.sock

  - name: Join the worker node to the kubernetes cluster
    become: true
    command: kubeadm join {{ master_ip_address }}:6443 --token {{ kubeadm_join_token }}  --cri-socket /run/cri-dockerd.sock --discovery-token-unsafe-skip-ca-verification
